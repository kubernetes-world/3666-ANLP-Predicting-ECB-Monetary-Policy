{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kubernetes-world/3666-ANLP-Predicting-ECB-Monetary-Policy/blob/main/LSTM_2_cce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "collapsed": true,
        "id": "z_BjdltLgsjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmWJTYWx7Ibd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import gensim\n",
        "import unicodedata\n",
        "\n",
        "from itertools import groupby\n",
        "from unicodedata import category as unicat\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.chunk import tree2conlltags\n",
        "from nltk.chunk.regexp import RegexpParser\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from tensorflow.keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class KeyphraseExtractor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Extract adverbial and adjective phrases, and transform\n",
        "    documents into lists of these keyphrases, with a total\n",
        "    keyphrase lexicon limited by the nfeatures parameter\n",
        "    and a document length limited/padded to doclen\n",
        "    \"\"\"\n",
        "    def __init__(self, nfeatures: int, doclen: int):\n",
        "        self.grammar = r'KT: {(<RB.> <JJ.*>|<VB.*>|<RB.*>)|(<JJ> <NN.*>)}'\n",
        "        # self.grammar = r'KT: {(<RB.*> <VB.>|<RB.>|<JJ.> <NN.*>)}'\n",
        "        # self.grammar = r'KT: {<RB.>|<JJ.>}'\n",
        "        self.chunker = RegexpParser(self.grammar)\n",
        "        self.nfeatures = nfeatures\n",
        "        self.doclen = doclen\n",
        "        self._curr = 0\n",
        "\n",
        "    def normalize(self, sent):\n",
        "        \"\"\"\n",
        "        Removes punctuation from a tokenized/tagged sentence and\n",
        "        lowercases words.\n",
        "        \"\"\"\n",
        "        is_punct = lambda word: all(unicat(c).startswith('P') for c in word)\n",
        "        sent = filter(lambda t: not is_punct(t[0]), sent)\n",
        "        sent = map(lambda t: (t[0].lower(), t[1]), sent)\n",
        "        return list(sent)\n",
        "\n",
        "    def extract_candidate_phrases(self, sents, call_no):\n",
        "        \"\"\"\n",
        "        For a document, parse sentences using our chunker created by\n",
        "        our grammar, converting the parse tree into a tagged sequence.\n",
        "        Extract phrases, rejoin with a space, and yield the document\n",
        "        represented as a list of it's keyphrases.\n",
        "        \"\"\"\n",
        "        print(f\">> \\t [{call_no}] extract_candidate_phrases...\")\n",
        "\n",
        "        for i, sent in enumerate(sents):\n",
        "            tokens = word_tokenize(sent)\n",
        "            pos_tags = pos_tag(tokens)\n",
        "            normalized = self.normalize(pos_tags)\n",
        "            # print(f\"[{self._curr}] sent #{i}: {sent}\")\n",
        "            # print(f\"[{self._curr}] \\t {normalized}\")\n",
        "\n",
        "            chunks = tree2conlltags(self.chunker.parse(normalized))\n",
        "            if not chunks or all(chunk[-1] == 'O' for chunk in chunks):\n",
        "                #print(f\"No valid chunks found in sentence: {sent}\")\n",
        "                continue\n",
        "\n",
        "            phrases = [\n",
        "                \" \".join(word for word, pos, chunk in group).lower()\n",
        "                for key, group in groupby(\n",
        "                    chunks, lambda term: term[-1] != 'O'\n",
        "                ) if key\n",
        "            ]\n",
        "            for phrase in phrases:\n",
        "                yield phrase\n",
        "\n",
        "    def fit(self, documents, y=None):\n",
        "        return self\n",
        "\n",
        "    def get_lexicon(self, keydocs):\n",
        "        \"\"\"\n",
        "        Build a lexicon of size nfeatures\n",
        "        \"\"\"\n",
        "        keyphrases = [keyphrase for doc in keydocs for keyphrase in doc]\n",
        "        print(\"Keyphrases:\", keyphrases[:5])\n",
        "        fdist = FreqDist(keyphrases)\n",
        "        counts = fdist.most_common(self.nfeatures)\n",
        "        print(\"Frequency counts:\", counts[:5])\n",
        "        lexicon = [phrase for phrase, count in counts]\n",
        "        return {phrase: idx+1 for idx, phrase in enumerate(lexicon)}\n",
        "\n",
        "    def clip(self, keydoc, lexicon):\n",
        "        \"\"\"\n",
        "        Remove keyphrases from documents that aren't in the lexicon\n",
        "        \"\"\"\n",
        "        return [lexicon[keyphrase] for keyphrase in keydoc\n",
        "            if keyphrase in lexicon.keys()]\n",
        "\n",
        "    def transform(self, documents):\n",
        "      self._curr += 1\n",
        "      print(f\">> [{self._curr}] KeyphraseExtractor.transform: {len(documents)}...\")\n",
        "      docs = [list(self.extract_candidate_phrases(doc, i)) for i, doc in enumerate(documents)]\n",
        "      lexicon = self.get_lexicon(docs)\n",
        "      clipped = [list(self.clip(doc, lexicon)) for doc in docs]\n",
        "      return pad_sequences(clipped, maxlen=self.doclen)"
      ],
      "metadata": {
        "id": "T0tWYGJmIAIl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dropout, Dense, Input\n",
        "\n",
        "def create_lstm_model(vocab_size: int, input_length: int, num_classes: int, compile_loss: str):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_length,), name=\"input_layer\"),  # explicit input layer\n",
        "        Embedding(input_dim=vocab_size, output_dim=128, name=\"embedding_layer\"),\n",
        "        LSTM(128, return_sequences=True, name=\"lstm_layer_1\"),\n",
        "        Dropout(0.2, name=\"dropout_layer_1\"),\n",
        "        LSTM(64, name=\"lstm_layer_2\"),\n",
        "        Dropout(0.2, name=\"dropout_layer_2\"),\n",
        "        Dense(num_classes, activation=\"softmax\", name=\"output_layer\")\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss=compile_loss, metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ghUGperddEGg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DebugTransformer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        print(\"Data Shape Before LSTM:\", X.shape)\n",
        "        # print(\"Sample Data Before LSTM:\", X[0])  # print a sample\n",
        "        return X\n"
      ],
      "metadata": {
        "id": "Z9Oezl_Klq9B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from joblib import Memory\n",
        "\n",
        "# set up caching directory\n",
        "memory = Memory(location=\"cache_directory\", verbose=0)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    # (\"keyphrase_extractor\", # don't do this!, pre-compute this step instead!!!\n",
        "    #   KeyphraseExtractor(nfeatures=10000, doclen=100)),\n",
        "    ('debug', DebugTransformer()),\n",
        "    (\"lstm_classifier\",\n",
        "      KerasClassifier(\n",
        "        build_fn=create_lstm_model,\n",
        "        vocab_size=10000,\n",
        "        input_length=100,\n",
        "        num_classes=3,\n",
        "        compile_loss='categorical_crossentropy',\n",
        "        epochs=10,\n",
        "        batch_size=32,\n",
        "        verbose=1)\n",
        "    )\n",
        "], memory=memory)\n"
      ],
      "metadata": {
        "id": "BqOg4fG8YtYV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_transformed = np.load(\"X_transformed.npy\")\n",
        "print(f\"X_transformed.shape: {X_transformed.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPRAMOYqiWQ5",
        "outputId": "973f084d-2c77-425c-a595-da70108463bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_transformed.shape: (3434, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use to_categorical():\n",
        "# If your model requires one-hot encoded labels (e.g., TensorFlow/Keras models with categorical_crossentropy loss).\n",
        "# Converts class indices (integers) to a binary matrix for one-hot encoding.\n",
        "\n",
        "y_categorical = np.load(\"y_categorical.npy\")\n",
        "print(f\"y_categorical.shape: {y_categorical.shape}\")\n"
      ],
      "metadata": {
        "id": "b4CE1AT6uGZ_",
        "outputId": "38f63631-7d24-4e14-dd8f-c1f2199fd2f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_categorical.shape: (3434, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choices for `n_splits`\n",
        "\n",
        "## 5-Fold Cross-Validation:\n",
        "- Most commonly used.\n",
        "- Provides a good balance between bias and variance of the performance estimate.\n",
        "\n",
        "## 10-Fold Cross-Validation:\n",
        "- Preferred when data is limited and computational cost is acceptable.\n",
        "- Offers slightly more robust performance estimates but increases computation time."
      ],
      "metadata": {
        "id": "uc8uSOcwmX1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# dynamically determine n_splits based on class distribution\n",
        "# min_class_size = rate_speeches[\"Direction\"].value_counts().min()\n",
        "# print(f\"min_class_size: {min_class_size}\")\n",
        "n_splits = 10 # min(10, min_class_size)  # use up to 10 splits or the smallest class size\n",
        "print(f\"Using {n_splits}-Fold Cross-Validation\")\n",
        "\n",
        "tss = TimeSeriesSplit(n_splits=n_splits)\n"
      ],
      "metadata": {
        "id": "ub3UMSYFZJY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87b2a13-65c2-46e4-929e-458ca540808b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 10-Fold Cross-Validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_transformed, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "scores = cross_val_score(pipeline, X_train, y_train, cv=tss, scoring=\"accuracy\")\n"
      ],
      "metadata": {
        "id": "pYDdKRsfYQLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3321e31-49fc-4cc2-dad5-83f5bfd58317"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6795 - loss: 1.0251\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8189 - loss: 0.7301\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8414 - loss: 0.5414\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8462 - loss: 0.5219\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8339 - loss: 0.4324\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9220 - loss: 0.2176\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9102 - loss: 0.1679\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9129 - loss: 0.1331\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9617 - loss: 0.0925\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9584 - loss: 0.1245\n",
            "Data Shape Before LSTM: (249, 100)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7313 - loss: 0.9249\n",
            "Epoch 2/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8478 - loss: 0.5196\n",
            "Epoch 3/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8666 - loss: 0.4233\n",
            "Epoch 4/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9064 - loss: 0.2200\n",
            "Epoch 5/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9360 - loss: 0.1334\n",
            "Epoch 6/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9247 - loss: 0.1296\n",
            "Epoch 7/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9570 - loss: 0.0941\n",
            "Epoch 8/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9867 - loss: 0.0632\n",
            "Epoch 9/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9630 - loss: 0.1153\n",
            "Epoch 10/10\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9955 - loss: 0.0411\n",
            "Data Shape Before LSTM: (249, 100)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7641 - loss: 0.8641\n",
            "Epoch 2/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8468 - loss: 0.5377\n",
            "Epoch 3/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8489 - loss: 0.4797\n",
            "Epoch 4/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9078 - loss: 0.2138\n",
            "Epoch 5/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9387 - loss: 0.1315\n",
            "Epoch 6/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9377 - loss: 0.1222\n",
            "Epoch 7/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9606 - loss: 0.0916\n",
            "Epoch 8/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0533\n",
            "Epoch 9/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9978 - loss: 0.0250\n",
            "Epoch 10/10\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0126\n",
            "Data Shape Before LSTM: (249, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b9fd7fe1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7589 - loss: 0.8153\n",
            "Epoch 2/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8320 - loss: 0.5314\n",
            "Epoch 3/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8887 - loss: 0.2534\n",
            "Epoch 4/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9174 - loss: 0.1532\n",
            "Epoch 5/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9263 - loss: 0.1457\n",
            "Epoch 6/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0630\n",
            "Epoch 7/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9959 - loss: 0.0335\n",
            "Epoch 8/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0068\n",
            "Epoch 9/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9988 - loss: 0.0047\n",
            "Epoch 10/10\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9981 - loss: 0.0063\n",
            "Data Shape Before LSTM: (249, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b9fdff3e560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7826 - loss: 0.8110\n",
            "Epoch 2/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8378 - loss: 0.5305\n",
            "Epoch 3/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9030 - loss: 0.2413\n",
            "Epoch 4/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9311 - loss: 0.1424\n",
            "Epoch 5/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9799 - loss: 0.0748\n",
            "Epoch 6/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0239\n",
            "Epoch 7/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0182\n",
            "Epoch 8/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9982 - loss: 0.0180\n",
            "Epoch 9/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0046\n",
            "Epoch 10/10\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0131\n",
            "Data Shape Before LSTM: (249, 100)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7911 - loss: 0.7751\n",
            "Epoch 2/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8391 - loss: 0.5172\n",
            "Epoch 3/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9027 - loss: 0.2442\n",
            "Epoch 4/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9264 - loss: 0.1424\n",
            "Epoch 5/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.0616\n",
            "Epoch 6/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0297\n",
            "Epoch 7/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9989 - loss: 0.0141\n",
            "Epoch 8/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0153\n",
            "Epoch 9/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0087\n",
            "Epoch 10/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0033\n",
            "Data Shape Before LSTM: (249, 100)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7987 - loss: 0.7490\n",
            "Epoch 2/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8359 - loss: 0.5295\n",
            "Epoch 3/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9122 - loss: 0.2096\n",
            "Epoch 4/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9546 - loss: 0.1224\n",
            "Epoch 5/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0386\n",
            "Epoch 6/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9979 - loss: 0.0180\n",
            "Epoch 7/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0122\n",
            "Epoch 8/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0066\n",
            "Epoch 9/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0252\n",
            "Epoch 10/10\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0043\n",
            "Data Shape Before LSTM: (249, 100)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8117 - loss: 0.7287\n",
            "Epoch 2/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8478 - loss: 0.4973\n",
            "Epoch 3/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9075 - loss: 0.2558\n",
            "Epoch 4/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9478 - loss: 0.1350\n",
            "Epoch 5/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9809 - loss: 0.0707\n",
            "Epoch 6/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0139\n",
            "Epoch 7/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0081\n",
            "Epoch 8/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9989 - loss: 0.0108\n",
            "Epoch 9/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0100\n",
            "Epoch 10/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0030\n",
            "Data Shape Before LSTM: (249, 100)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8177 - loss: 0.6886\n",
            "Epoch 2/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8502 - loss: 0.4528\n",
            "Epoch 3/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8938 - loss: 0.2105\n",
            "Epoch 4/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9385 - loss: 0.1367\n",
            "Epoch 5/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9829 - loss: 0.0535\n",
            "Epoch 6/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0132\n",
            "Epoch 7/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0162\n",
            "Epoch 8/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0077\n",
            "Epoch 9/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0038\n",
            "Epoch 10/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0036\n",
            "Data Shape Before LSTM: (249, 100)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8068 - loss: 0.6991\n",
            "Epoch 2/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8414 - loss: 0.4790\n",
            "Epoch 3/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8980 - loss: 0.2238\n",
            "Epoch 4/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9407 - loss: 0.1283\n",
            "Epoch 5/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.0546\n",
            "Epoch 6/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 0.0312\n",
            "Epoch 7/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9956 - loss: 0.0227\n",
            "Epoch 8/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0113\n",
            "Epoch 9/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9981 - loss: 0.0087\n",
            "Epoch 10/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0042\n",
            "Data Shape Before LSTM: (249, 100)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Cross-validation scores: {scores}\")\n",
        "print(f\"Mean accuracy: {np.mean(scores):.2f}\")\n"
      ],
      "metadata": {
        "id": "aamEA-X7addX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c6bb6d-6c02-46f7-bc9a-385c01061f4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.83935743 0.8313253  0.77911647 0.80321285 0.82329317 0.85943775\n",
            " 0.70281124 0.81927711 0.77911647 0.77911647]\n",
            "Mean accuracy: 0.80\n"
          ]
        }
      ]
    }
  ]
}