{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0ca137-036c-4c95-b017-229f7c120e10",
   "metadata": {},
   "source": [
    "# SCS_3666_018 Applied Natural Language Processing - Final Project\n",
    "### Predicting ECB rate changes based on speeches leading up to monetary policy rate decision meetings\n",
    "\n",
    "Speech data sourced from Kaggle:\n",
    "https://www.kaggle.com/datasets/robertolofaro/ecb-speeches-1997-to-20191122-frequencies-dm\n",
    "\n",
    "Rate change data sourced from ECB website: \n",
    "https://www.ecb.europa.eu/stats/policy_and_exchange_rates/key_ecb_interest_rates/html/index.en.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e7baa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: r:\\HSPS\\DDS\\NLP Course\\Final Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the current working directory\n",
    "project_path = r\"R:\\HSPS\\DDS\\NLP Course\\Final Project\"\n",
    "os.chdir(project_path)\n",
    "\n",
    "# Verify the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4f50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614d3151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   speech_id when_speech                     who  \\\n",
      "0       2748  1999-03-04    Willem F. Duisenberg   \n",
      "1         80  1999-03-08         Christian Noyer   \n",
      "2         81  1999-03-09  Tommaso Padoa-Schioppa   \n",
      "3         82  1999-03-10  Eugenio Domingo Solans   \n",
      "4         83  1999-03-12    Willem F. Duisenberg   \n",
      "\n",
      "                                     what_title  \\\n",
      "0               Introductory statement with Q&A   \n",
      "1               First experiences with the euro   \n",
      "2  The euro: significance for Europe and beyond   \n",
      "3              The euro as a new world currency   \n",
      "4        The Eurosystem's strategy for the euro   \n",
      "\n",
      "                                    what_frequencies what_language  \\\n",
      "0  {\"euro\":45,\"question\":33,\"rate\":30,\"duisenberg...            EN   \n",
      "1  {\"monetary\":64,\"euro\":51,\"price\":48,\"policy\":4...            EN   \n",
      "2  {\"euro\":29,\"currency\":20,\"monetary\":15,\"single...            EN   \n",
      "3  {\"euro\":63,\"currency\":29,\"area\":23,\"monetary\":...            EN   \n",
      "4  {\"monetary\":50,\"stability\":35,\"policy\":35,\"pri...            EN   \n",
      "\n",
      "                                        what_weblink what_type Meeting Dates  \\\n",
      "0  https://www.ecb.europa.eu/press/pressconf/1999...         P    1999-03-04   \n",
      "1  https://www.ecb.europa.eu/press/key/date/1999/...         S    1999-04-08   \n",
      "2  https://www.ecb.europa.eu/press/key/date/1999/...         S    1999-04-08   \n",
      "3  https://www.ecb.europa.eu/press/key/date/1999/...         S    1999-04-08   \n",
      "4  https://www.ecb.europa.eu/press/key/date/1999/...         S    1999-04-08   \n",
      "\n",
      "  Rate Change Date  Main refinancing operations - fixed rate tenders  \\\n",
      "0              NaN                                               3.0   \n",
      "1           4/9/99                                               2.5   \n",
      "2           4/9/99                                               2.5   \n",
      "3           4/9/99                                               2.5   \n",
      "4           4/9/99                                               2.5   \n",
      "\n",
      "   Change (%)  Direction  is_col2_earlier  same_date  \\\n",
      "0         0.0  No Change            False       True   \n",
      "1        -0.5   Decrease            False      False   \n",
      "2        -0.5   Decrease            False      False   \n",
      "3        -0.5   Decrease            False      False   \n",
      "4        -0.5   Decrease            False      False   \n",
      "\n",
      "                                      extracted_text  \\\n",
      "0  Willem F. Duisenberg, President of the Europea...   \n",
      "1  Speech by Christian Noyer, Vice-President of t...   \n",
      "2  Speech by Tommaso Padoa-Schioppa Member of the...   \n",
      "3  Eugenio Domingo Solans, Member of the Executiv...   \n",
      "4  Speech by Dr. Willem F. Duisenberg, President ...   \n",
      "\n",
      "                                     normalized_text  \n",
      "0  [willem, f, duisenberg, president, european, c...  \n",
      "1  [speech, christian, noyer, vicepresident, euro...  \n",
      "2  [speech, tommaso, padoaschioppa, member, execu...  \n",
      "3  [eugenio, domingo, solans, member, executive, ...  \n",
      "4  [speech, dr, willem, f, duisenberg, president,...  \n"
     ]
    }
   ],
   "source": [
    "# Read the Pickle file\n",
    "loaded_data = pd.read_pickle(r'R:\\HSPS\\DDS\\NLP Course\\Final Project\\ECB_Speeches_Normalized.pkl')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(loaded_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2162b-4ba3-41d6-b506-77c9a40fb3cd",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82a352e7-298b-4f19-8134-77a6ff3a84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loaded_data['extracted_text']\n",
    "y = loaded_data['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa020ef-2519-4256-b26c-db27c99f06e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mapping = {\n",
    "    'No Change': 0,\n",
    "    'Increase': 1,\n",
    "    'Decrease': 2\n",
    "}\n",
    "\n",
    "y= y.map(label_mapping).values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902cdeea",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8741528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b0ecf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance manually\n",
    "train_data = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "\n",
    "# Separate classes\n",
    "class_0 = train_data[train_data['label'] == 0]\n",
    "class_1 = train_data[train_data['label'] == 1]\n",
    "class_2 = train_data[train_data['label'] == 2]\n",
    "\n",
    "# Oversample minority classes to match the majority class\n",
    "class_1_oversampled = resample(class_1, \n",
    "                               replace=True, \n",
    "                               n_samples=len(class_0), \n",
    "                               random_state=42)\n",
    "class_2_oversampled = resample(class_2, \n",
    "                               replace=True, \n",
    "                               n_samples=len(class_0), \n",
    "                               random_state=42)\n",
    "\n",
    "# Combine oversampled classes with majority class\n",
    "train_data_balanced = pd.concat([class_0, class_1_oversampled, class_2_oversampled])\n",
    "\n",
    "# Split back into features and labels\n",
    "X_train_balanced = train_data_balanced['text']\n",
    "y_train_balanced = train_data_balanced['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0c42896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the balanced training data\n",
    "X_train_balanced_tfidf = vectorizer.transform(X_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "595a4931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Logistic Regression model with class weights\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train_balanced_tfidf, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fad230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Change       0.93      0.84      0.88       578\n",
      "    Increase       0.46      0.74      0.57        50\n",
      "    Decrease       0.33      0.47      0.39        59\n",
      "\n",
      "    accuracy                           0.80       687\n",
      "   macro avg       0.57      0.68      0.61       687\n",
      "weighted avg       0.84      0.80      0.81       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model\n",
    "print(classification_report(y_test, y_pred, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab5d28",
   "metadata": {},
   "source": [
    "## Gboosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38e9b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e62ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_pickle(r'R:\\HSPS\\DDS\\NLP Course\\Final Project\\ECB_Speeches_Normalized.pkl')\n",
    "X = data['extracted_text']\n",
    "y = data['Direction']\n",
    "\n",
    "# Map labels to numeric values\n",
    "label_mapping = {'No Change': 0, 'Increase': 1, 'Decrease': 2}\n",
    "y = y.map(label_mapping)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2), stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02943f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [06:54:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Change       0.88      0.99      0.93       578\n",
      "    Increase       0.88      0.42      0.57        50\n",
      "    Decrease       0.83      0.08      0.15        59\n",
      "\n",
      "    accuracy                           0.87       687\n",
      "   macro avg       0.86      0.50      0.55       687\n",
      "weighted avg       0.87      0.87      0.84       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=len(y_train) / y_train.value_counts().values,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"XGBoost Results:\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35f890a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad8b78e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 640943\n",
      "[LightGBM] [Info] Number of data points in the train set: 2747, number of used features: 9893\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "LightGBM Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Change       0.89      0.98      0.93       578\n",
      "    Increase       0.74      0.58      0.65        50\n",
      "    Decrease       0.64      0.15      0.25        59\n",
      "\n",
      "    accuracy                           0.88       687\n",
      "   macro avg       0.76      0.57      0.61       687\n",
      "weighted avg       0.86      0.88      0.85       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Train LightGBM model\n",
    "lgbm_model = LGBMClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "lgbm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgbm = lgbm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"LightGBM Results:\")\n",
    "print(classification_report(y_test, y_pred_lgbm, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22c21abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51cfea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0862688\ttotal: 1.8s\tremaining: 14m 59s\n",
      "100:\tlearn: 0.5561947\ttotal: 2m 10s\tremaining: 8m 36s\n",
      "200:\tlearn: 0.2844287\ttotal: 4m 23s\tremaining: 6m 32s\n",
      "300:\tlearn: 0.1812209\ttotal: 6m 36s\tremaining: 4m 22s\n",
      "400:\tlearn: 0.1344899\ttotal: 8m 48s\tremaining: 2m 10s\n",
      "499:\tlearn: 0.1072718\ttotal: 11m 1s\tremaining: 0us\n",
      "CatBoost Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Change       0.91      0.92      0.91       578\n",
      "    Increase       0.51      0.68      0.58        50\n",
      "    Decrease       0.43      0.25      0.32        59\n",
      "\n",
      "    accuracy                           0.84       687\n",
      "   macro avg       0.61      0.62      0.60       687\n",
      "weighted avg       0.84      0.84      0.84       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Train CatBoost model\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    class_weights=[1, len(y_train) / y_train.value_counts()[1], len(y_train) / y_train.value_counts()[2]],\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "catboost_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_catboost = catboost_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"CatBoost Results:\")\n",
    "print(classification_report(y_test, y_pred_catboost, target_names=label_mapping.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6490c0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [07:09:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.141321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 640943\n",
      "[LightGBM] [Info] Number of data points in the train set: 2747, number of used features: 9893\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "0:\tlearn: 1.0862688\ttotal: 1.52s\tremaining: 12m 37s\n",
      "100:\tlearn: 0.5561947\ttotal: 2m 8s\tremaining: 8m 26s\n",
      "200:\tlearn: 0.2844287\ttotal: 4m 20s\tremaining: 6m 27s\n",
      "300:\tlearn: 0.1812209\ttotal: 6m 32s\tremaining: 4m 19s\n",
      "400:\tlearn: 0.1344899\ttotal: 8m 43s\tremaining: 2m 9s\n",
      "499:\tlearn: 0.1072718\ttotal: 10m 53s\tremaining: 0us\n",
      "Ensemble Voting Classifier Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Change       0.89      0.98      0.93       578\n",
      "    Increase       0.78      0.56      0.65        50\n",
      "    Decrease       0.71      0.17      0.27        59\n",
      "\n",
      "    accuracy                           0.88       687\n",
      "   macro avg       0.79      0.57      0.62       687\n",
      "weighted avg       0.87      0.88      0.86       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define the ensemble\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgbm', lgbm_model),\n",
    "        ('catboost', catboost_model)\n",
    "    ],\n",
    "    voting='soft'  # Use probabilities for better performance\n",
    ")\n",
    "voting_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate ensemble model\n",
    "print(\"Ensemble Voting Classifier Results:\")\n",
    "print(classification_report(y_test, y_pred_voting, target_names=label_mapping.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d30003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Load data\n",
    "data = pd.read_pickle(r'R:\\HSPS\\DDS\\NLP Course\\Final Project\\ECB_Speeches_Normalized.pkl')\n",
    "X = data['extracted_text']\n",
    "y = data['Direction']\n",
    "\n",
    "# Map labels to numeric values\n",
    "label_mapping = {'No Change': 0, 'Increase': 1, 'Decrease': 2}\n",
    "y = y.map(label_mapping)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Combine training data for oversampling\n",
    "train_data = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "\n",
    "# Separate classes\n",
    "class_0 = train_data[train_data['label'] == 0]\n",
    "class_1 = train_data[train_data['label'] == 1]\n",
    "class_2 = train_data[train_data['label'] == 2]\n",
    "\n",
    "# Oversample minority classes\n",
    "class_1_oversampled = resample(class_1, replace=True, n_samples=len(class_0), random_state=42)\n",
    "class_2_oversampled = resample(class_2, replace=True, n_samples=len(class_0), random_state=42)\n",
    "\n",
    "# Combine oversampled data with majority class\n",
    "train_data_balanced = pd.concat([class_0, class_1_oversampled, class_2_oversampled])\n",
    "\n",
    "# Split back into features and labels\n",
    "X_train_balanced = train_data_balanced['text']\n",
    "y_train_balanced = train_data_balanced['label']\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1, 3), stop_words='english')\n",
    "X_train_balanced_tfidf = vectorizer.fit_transform(X_train_balanced)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Define base models with class weights\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=len(y_train_balanced) / y_train_balanced.value_counts().values,  # Adjust weights\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_model = LGBMClassifier(\n",
    "    class_weight='balanced',  # Auto-adjust weights\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "catboost_model = CatBoostClassifier(\n",
    "    class_weights=[1, len(y_train_balanced) / y_train_balanced.value_counts()[1], len(y_train_balanced) / y_train_balanced.value_counts()[2]],\n",
    "    iterations=500,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Ensemble Voting Classifier with weighted voting\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('lgbm', lgbm_model),\n",
    "        ('catboost', catboost_model)\n",
    "    ],\n",
    "    voting='soft',  # Use predicted probabilities\n",
    "    weights=[1, 1, 2]  # Assign higher weight to CatBoost for minority classes\n",
    ")\n",
    "\n",
    "# Train the voting model\n",
    "voting_model.fit(X_train_balanced_tfidf, y_train_balanced)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_voting = voting_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate ensemble model\n",
    "print(\"Improved Ensemble Voting Classifier Results:\")\n",
    "print(classification_report(y_test, y_pred_voting, target_names=label_mapping.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
